(텍스트 기반 중심)

### 🧩 1. **분류 체계 설계**

| 분류          | 주요 항목                         | 예시                                                     | 처리 우선순위        | 탐지 기준              |
| ----------- | ----------------------------- | ------------------------------------------------------ | -------------- | ------------------ |
| **고유식별정보**  | 주민등록번호, 여권번호, 운전면허번호, 외국인등록번호 | 900101-1234567, 11-99-123456-10                        | 🔴 최우선 삭제      | 정규표현식, 패턴고정        |
| **직접식별정보**  | 성명, 연락처, 계좌번호, 사진, 생체정보 등     | 홍길동, 010-1234-5678, 신한 12345678                        | 🔴 삭제 또는 마스킹   | 명사 패턴 + 엔터티 사전/NER |
| **간접식별정보**  | 주소, 생년월일, 직업, 가족관계 등          | 서울시 강남구, 간호사, 1990년생, 남편                               | 🟡 필요시 가명처리    | NER, 패턴기반 + 문맥조건   |
| **민감정보**    | 병력, 종교, 정치성향, 범죄이력 등          | 우울증, 개신교, 민주당 지지자, 전과 2범                               | 🔴 삭제 또는 별도 분리 | 키워드사전 + 감성분석 기반    |
| **기타 기술정보** | IP, 이메일, 기기ID 등               | 192.168.1.1, [user@domain.com](mailto:user@domain.com) | 🟠 일부 마스킹      | 정규표현식, 후처리 분기      |

---

### 🧠 2. 탐지 방법 설계

#### 🔹 A. **정규표현식 기반 탐지 (고정 패턴 정보)**

|항목|패턴 예시|
|---|---|
|주민등록번호|`\b\d{6}[-]?\d{7}\b`|
|전화번호|`\b01[0-9]-?\d{3,4}-?\d{4}\b`|
|여권번호|`\b[A-Z]{1}[0-9]{8}\b`|
|이메일|`\b[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+\b`|
|IP 주소|`\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b`|

#### 🔹 B. **NER 기반 탐지 (의미 단위 탐지)**

- 모델: `KoBERT`, `klue/ner`, 사내 fine-tuned NER
    
- 엔티티 라벨 예시:
    - PER (인물명), LOC (지역), ORG (조직), DATE, TIME, ADDRESS
        
- 예시 문장:
    > "홍길동님은 서울시 강남구에 거주하며, 1990년생입니다."  
    > → `홍길동(PER), 서울시 강남구(LOC/ADDRESS), 1990년생(DATE)`
    

[[AI 기반 데이터 프라이버시 – 언어모델을 이용한 개체명 인식과 개인정보 가명처리]]



#### 🔹 C. **사전 기반 키워드 탐지 (민감정보 중심)**

- 키워드 리스트 (커스터마이징 가능)
    
    - 병력: "우울증", "고혈압", "암", "장애"
    - 종교: "기독교", "불교", "무슬림"
    - 성향: "진보", "보수", "민주당", "국민의힘"
        
- 단순 탐지 외에 문맥 검토:  
    예) "암 걸렸어요" → 민감정보 확정  
    "암 예방 교육" → 제거 제외 가능
    

#### 🔹 D. **문맥 기반 룰 엔진 보완**

- 예) "저는 김민수에요" → 명사 ‘김민수’는 PER로 추정
    
- 단, "김민수 님의 사원번호는 1023입니다."  
    → 연속된 패턴일 때 식별자 정보로 강화 판단
    

---

### 🔄 3. 후처리 정책 기획

| 분류     | 처리 방식            | 비고                             |
| ------ | ---------------- | ------------------------------ |
| 고유식별정보 | **삭제 처리**        | 예외 없음 (주민등록번호 등)               |
| 직접식별정보 | 마스킹 또는 삭제        | ex: 홍길동 → 홍○○ / 010-****-5678  |
| 간접식별정보 | 가명처리 또는 일반화      | ex: 강남구 → 서울시 / 1990년생 → 90년대생 |
| 민감정보   | 삭제 또는 민감 레벨 태깅   | ex: (민감) 우울증 → [민감] 정신건강 이슈    |
| 기타 정보  | 식별 가능성에 따라 분기 처리 | ex: ID는 탈식별화 보관 가능 여부 검토       |

---

### 🧪 4. 테스트/검증 로직

- 정량 기준:
    
    - 탐지 정확도(Precision), 재현율(Recall)
        
    - 재식별 위험도 평가 결과
        
- 샘플 문장셋 테스트:
    
    - 상담 음성 → 텍스트 전사 → 탐지 후 비식별화 결과 확인
        
    - `Before / After` 로그 보관
        
- 적정성 검토 체크리스트 항목과 연결:
    
    - 예: "이 항목은 결합으로 재식별 가능성이 있는가?" (Y/N)
        

---

## ✍️ 부록: 적용 시나리오 예

```text
[원문]
"홍길동 고객님, 서울시 강남구에서 1990년 1월에 진료 받으셨습니다. 현재는 우울증 치료를 받고 계시며 연락처는 010-1234-5678입니다."

[비식별 처리 결과]
"[고객명] 고객님, 서울시에서 90년대 초반에 진료 받으셨습니다. 현재는 [정신건강이슈] 치료를 받고 계시며 연락처는 010-****-5678입니다."
```

---

필요하시면 위 로직을 **코드화(Python + 정규식 + NER 예제)**하거나,  
**DataScan 솔루션 내에서의 설계도/화면 구성**으로 연결도 도와드릴게요.