- 제목1: MongoDB 기반 API 로그 분석 대시보드의 성능 최적화
- 제목2 : MongoDB 쿼리 최적화를 위한 Aggregation Framework


### 발표 시작 전 소개


- MongoDB 최적화를 위한 Aggregation에 대해서 발표할 예정

1. Aggregation
2. Join
3. Merge
4. Unionwith

- 1) Aggregation이 find와 어떤 부분이 다른지
- 2) 조인 연산을 몽고DB에서 어떻게 처리할 수 있는지
- 3) 머지를 통해서 여러 가지  데이터 셋을 어떻게 하나의 타겟 컬렉션으로 넘길 수 있는지
- 4) 유니언 위드를 통해 서로 다른 스키마 구조의 컬렉션이 있을 때 어떻게 하나의 싱글 뷰로 볼 수 있는지

## 1. Aggregation 기본

![[Pasted image 20250311214516.png]]

- Aggregation이란 무엇인가?
	- 집계는 MongoDB가 데이터를 중심으로 복잡한 알고리즘을 관리하는 방식이다.
	- 파이프라인을 통과하는 문서의 필터링, 정렬, 그룹화, 재구성 및 변경이 모두 가능하다.
	- 일반 쿼리 프레임워크 내에 존재하지 않는 절차적 기능을 제공한다.
	- 파이프라인을 통해 단계에 따라 새로운 값을 계산하고 처리할 수 있다.
		- 연산된 필드
		- 요약 및 그룹화 된 값
		- 도큐먼트의 구조 변경

- 
	- 

### Pipeline?

- 
- 각각의파이프는 하나의 변환 단계를 거친다.
- 하나의 거대한 SQL 문장이 아니기 때문에 
- 왜 Aggregation을 사용하는지? 
	- 파이프라인 별로 연산 결과를 확인할 수 있기 때문에 디버깅하기 쉽다.
	- 파이프라인 별로 결과를 확인하고 원하는 대로 데이터를 조작하기 때문에 이해하기 쉽다.
	- 데이터베이스 계층이 아닌 애플리케이션 계층에 상주한다. 코드의 
	- mongoDB가 재 작성하거나 최적화할 수 있다.
	- Aggregation 파이프라인은 한 개 이상의 Stage로 구성
 

### SQL과 비교

- mongoDB find() 사용

```sql
SELECT a, b, c
FROM database.table
WHERE d<100
ORDER BY d ASC
```

```json
db.person.find(
	{ "주소.국가": "캐나다” '}, 
	{ "_id": 0, "나이': 1, "이름":1}
).sort(
	{ "나이": -1}
).limit(1)
```

- find는 SQL의 SELECT~WHERE ORDER BY와 동일하다.
- 단순 데이터를 조회하고 정렬해서 리턴하거나 인덱스를 걸어 페이지네이션 용도로 많이 사용한다.

---

- mongoDB aggregate() 사용

```sql
SELECT b+c AS a . SUM(e) AS t
FROM D.T1 LEFT JOIN D.T2 ON y
WHERE T2.A = T1.B
GROUP BY a
HAVING t > 100
```

```json
db.persons.aggregation([
	{ $match: { "주소.국가": "캐나다" } },
	{ $sort: { "연령": -1},
	{ $limit: 1},
	{ $project: { "_id": 0, "age": 1, "name": 1 }
])
```

- aggregation은 SQL SELECT GROUP BY , HAVING 과 같은 집계 연산을 구현할 수 있다.
- find로 할 수 있는 부분을 aggregation으로 처리할 수도 있고, 반대로 aggregation으로 표현할 수 있는 부분을 find로 표현 가능하다.
- 하지만 집계 연산이 복잡해지거나 도큐먼트를 변환해야 하는 요건이 많아짐에 따라 aggregation 사용 빈도가 높아질 수 밖에 없다.
- find 및 aggregation은 MongoDB에서 천천히 시험되고 있다.

- 정리
	- 데이터 조회가 단순 조회인 경우 find()를 사용하는 것이 더 효율적임
	- MongoDB 4.4부터 find에 project

- 위 두 방법은 동일한 출력을 생성하지만 스테이지의 순서가 해당 객체가 처리되는 순서를 결정하기 때문에 순서는 매우 중요하다.


```json
- Using find() method:

db.person.find(
	{ "address.country": "Canada” '}, 
	{ "host.host_tatal_listings_count": 1, "host.host_name":1})
.sort({ "host.host_tatal_listings_count": -1}).limit(1)

- **Using aggregate():**

db.persons.aggregate ([
	{ $match: { "address.country": "Canada" } },
	{ $project: { "host.host_tatal_listings_count": 0, "host.host_name": 1 }}
	{ $sort: { "host.host_tatal_listings_count": -1},
	{ $limit: 1},
	
])
```

- 2개 구문은 `address.country` 가 Canada인 도큐먼트를 찾아서 해당 도큐먼트에 2개의 필드 값만 `host_tatal_listings_count` 값이 큰  순으로 정렬 후 첫번째 도큐먼트를 리턴하는 예제 코드
- find 절은 필터링, 프로젝션으로 구성된 반면 aggregation에서는 match, project, sort, limit 과 같이 여러개 스테이지로 구성될 수 있다
	- find문이 작성하기 쉽고, API 로 구현하기 간단하다
	- 쿼리 조건이 복잡해지거나 중간에 산출하는 게 포함된 다면 aggregation이 좀 더 유리하다


## 2. JOIN Stage

![[Pasted image 20250311224426.png]]

- `$lookup`
- `$graphLookup`

- 관계형 DB의 Left Outer Join 또는 Nested Select 와 비슷하지만 관계형 DB처럼 사용하는 것은 MongoDB를 올바르게 사용하는 방법이 아니다.
- `$lookup` 연산을 사용하기 전에 스키마를 먼저 검토해야 한다.
- MongoDB에서 굳이 컬렉션 끼리 조인을 할 필요가 있을지
- 불가피하게 join이 필요하다면, 그때 `$lookup` 을 고려하는 것이 좋다.
- 데이터를 join할 때 연산비용이 발생하므로 , 좋은 도큐먼트 스키마 디자인이 더 중요하다
- join되는 컬렉션이 커질 수록 연산 비용이 증가한다.
- 때로는 임베딩하기에 데이터가 너무 빠르게 변경되고 임베딩된 필드에 대해서 항상 빈번한 업데이트를 하고 싶지 않을 때, 일대다 관계를 포함하고 있어서 임베딩이 최선의 방법이 아닌 경우가 생길 수 있다.
- 이 경우 `$lookup` 이 최선의 방법일 수 있다. 
- 2개의 콜렉션 필드를 가지고 join할 수도 있지만, 타겟 테이블에 aggregation을 추가한 뒤 연산을 처리한 결과를 가지고 join도 가능하다.
- 하나 이상의 컬렉션을 연속해서 `$lookup`할 수 있다.
- join되는 필드에 대한 indexing 및 튜닝이 필요하다.

### $Group

[참고 - MonoDB Group](https://www.mongodb.com/ko-kr/docs/manual/reference/operator/aggregation/group/)

- $bucket : 사전 정의된 범위 구간을 그룹핑
	- 추가 표현식 없이 특정 범위의 값을 그룹핑 가능
	- 예) 나이 필드 : 0~13세, 13~20세, 20~30세 등 범위로 그룹핑해서 count 등 
- $bucketAuto : N개의 유사 크기로 그룹핑
	- mongoDB가 자동으로 그룹핑하는 바운드를 정해줌
	- 필드에 대해 20개로 균등하게 그룹핑할 때, 필드에 대한 범위를 정하지 않고 그룹핑을 할 때 사용할 수 있음
	- 통계 옵션을 활용할 수 있고, 넓은 구간의 시계열 차트를 표현하는 데 유리함
- $facet : 여러 개의 서브 aggregation을 하나의 문서에 포함해서 리턴
	- 하나의 다큐먼트 내에서 결과를 받을 수 있음.
	- 예) 연도별 집계, 지역별 집계, 성별 집계 등 

### $sortByCount

```

```
- `$group`+`$sort`와 동일한 연산자이다.
- 단순 필드 값에 대한 카운트를 가지고 역정렬해서 보여주고자 할 때 두개의 파이프를 1개로 줄일 수 있는 연산자이다.


## 3.Merge Stage

- MongoDB 4.2부터 제공

## 4. UnionWith Stage

- MongoDB 4.4부터 제공
![[Pasted image 20250311230826.png]]
- RDB의 UNION ALL 연산자와 동일하고, RDB보다 좀 더 유연한 Union 을 한다.
- 기존 RDB Union All 연산 규칙
	- union하는 쿼리들의 컬럼 개수가 동일해야 함
	- union하는 쿼리들의 컬럼 순서가 동일해야 함
	- union하는 컬럼의 데이터 타입이 호환 가능해야 함
- MongoDB의 union Aggregation
	- 여러 컬렌션 및 파이프 라인의 데이터를 통합하여 심층적인 탐색 및 분석 가능
	- RDBMS의 제약에서 벗어나 스키마가 유연하고, 수평확장이 가능
- 사용 사례: 시계열 분석/ 싱글 뷰
	- 여러 데이터 소스에서 수집된 데이터를 통합하여 하나의 뷰로 계산 또는 리포팅
	- 월별로 개별 컬렉션에 저장된 센서 데이터를 통합하여 시간 경과에 따른 추세 분석


---

## 2. 문제 원인 분석 (7~8분)

### 현재 쿼리 방식과 병목 현상

![[Pasted image 20250311195703.png]]
- 현재 쿼리 구조:
    1. **첫 번째 콜렉션에서 `IN` 절과 `date` 변환 후 조건 검색**
    2. **나머지 3개 콜렉션에 동일한 조건을 적용 (파이프라인 사용)**
    3. **`$unionWith` 로 데이터를 병합**
- 병목 현상:
    - 인덱스가 없어서 모든 문서를 검색 (Full Collection Scan)
        - 어떤 필드에 인덱스가 없는 지?
    - **`$unionWith` 연산이 성능 저하를 유발** (대량 데이터 병합 시 부하 발생)
    - **불필요한 데이터 필터링 부족**으로 인해 더 많은 데이터가 쿼리 처리 과정에서 검색됨.

### 데이터가 많아질수록 성능 저하가 발생하는 원인

- **인덱스 부재**: 특정 필드 검색 시 **모든 문서를 대상으로 검색**하여 속도가 느려짐.
- **Aggregation 연산 부담**: `$match`, `$unionWith`, `$project` 등의 연산이 많아질수록 쿼리 실행 시간이 길어짐.
- **데이터 정렬(Sorting) 과정에서 추가적인 연산 부담 발생**, 메모리 사용량 증가.
- **MongoDB의 동적 스키마 특성으로 인해, 적절한 데이터 모델링이 이루어지지 않으면 성능 저하가 심각해질 가능성**이 있음.

### MongoDB의 특성 (인덱스, Aggregation 등)에 대한 이해 부족 문제

- **적절한 인덱스 적용 방식**에 대한 지식 부족
- **Aggregation Pipeline 최적화 기법** 미숙
- **MongoDB 내부 동작 방식 (Execution Plan 등)**에 대한 이해 부족
- **대규모 데이터에서 실행되는 쿼리의 최적화 기법 적용 미비**

---

## 3. 성능 최적화 방법 (7~10분)

### 1) 인덱싱 전략 개선

- **기본 인덱스 적용**
    - `int` 필드(IN 조건) + `date` 필드 복합 인덱스 추가
    - 예: `{ api_type: 1, date: -1 }`
- **Partial Index 활용** (자주 조회되는 조건만 인덱스 적용)
- **TTL Index 활용** (오래된 로그 자동 삭제하여 데이터 부담 감소)
- **Compound Index 추가**하여 여러 필드에 대한 검색 성능 개선

### 2) Aggregation Pipeline 최적화

- `$match`를 **초기 단계에서 적용**하여 불필요한 데이터 필터링 최소화
	- 왜? `$match`를 초기 단계에 적용하는 것이 중요한가?
	- (예: `Aggregation` 실행 시, **초기 `$match` 적용**이 없으면 불필요한 데이터가 많아져 이후 단계에서 성능 저하 발생)
- `$unionWith` 대신 **단일 콜렉션에 데이터 저장하는 방식 고려** (쿼리 비용 절감)
	- (예: 특정 API별로 별도 저장 vs. 하나의 로그 테이블로 통합했을 때 장단점)
- `$project` 연산을 최소화하여 불필요한 필드 제거
- **Lookup 연산 대신 denormalization(데이터 중복 저장) 고려**

### 3) MongoDB 실행 계획 분석 (Explain 사용)

- `db.collection.explain("executionStats").aggregate([...])` 명령어로 쿼리 성능 분석
- **Execution Plan 확인 후 느린 연산 식별 및 최적화**
- **Execution Plan에서 stage 별 처리 비용(cost) 분석 후 최적화 적용**

### 4) 샤딩(Sharding) 고려

- 트래픽이 많아질 경우 **수평 확장(Sharding)** 도입 검토
- 특정 필드를 기준으로 데이터 분산 저장하여 **쿼리 부하 분산**
- 샤딩을 적용하면 **읽기/쓰기 작업을 분산할 수 있으며**, 특정 서버의 부하를 줄일 수 있음.
- (예: "단일 인스턴스에서 초당 몇만 건 이상의 요청이 발생할 경우 샤딩을 검토해야 함.")

## 4. MongoDB 성능 최적화 시 고려해야 할 일반적인 방법

- **적절한 인덱싱 적용**: 단일 인덱스, 복합 인덱스, Partial Index, TTL Index 활용
- **쿼리 최적화**: `$match`를 앞단에서 적용, 불필요한 필드 제거, `$unionWith` 최소화
- **데이터 모델링 최적화**: 중복 저장(denormalization) 활용, 읽기/쓰기 성능 고려한 설계
- **실행 계획 분석(Explain 활용)**: 쿼리 실행 비용 분석 및 최적화
- **수평 확장(Sharding) 고려**: 대량 데이터 처리를 위한 샤딩 도입
- **캐싱 적용**: 자주 조회되는 데이터는 캐싱하여 성능 개선


---


## - 적용 사례 및 기대 효과 (3~5분)

### 우리가 시도해본 최적화 방법

- **인덱스 추가 후 쿼리 속도 개선**
    - 기존 Full Scan 대비 **조회 속도 최대 80% 향상**
- **Aggregation Pipeline 최적화 적용**
    - `$match` 연산을 앞단에서 적용하여 처리량 감소
    - `$unionWith` 사용 최소화 후 쿼리 실행 시간 단축
    - 복합 인덱스 추가 후 쿼리 실행 시간 단축

### 앞으로 개선할 수 있는 부분

- **MongoDB 내부 쿼리 분석 심화 학습**
- **샤딩 적용 여부 검토** (데이터 증가 대비)
- **로그 저장 구조 개선 (필요한 데이터만 유지하는 정책 적용)**
- **캐싱(Cache) 적용 검토** (자주 조회되는 데이터 미리 저장하여 성능 향상)

---

## 결론

MongoDB 기반의 API 로그 분석 대시보드에서 발생하는 성능 문제를 해결하기 위해 **인덱스 적용, Aggregation 최적화, 실행 계획 분석** 등의 기법을 활용할 수 있음. 앞으로도 지속적인 성능 개선을 통해 대용량 데이터 처리 효율을 높이는 것이 목표! 또한 **MongoDB의 최신 기능 활용, 데이터 모델링 개선, 샤딩과 캐싱 기법을 적극적으로 검토하여 최적화 방안을 마련할 필요가 있음**.

---

## 사용 x 


### DataScan MongoDB 사용 

- DataScan은 **비정형 데이터를 정형화하는 솔루션**으로, 다양한 형태의 데이터를 분류 규칙으로 정형화하여 일관된 데이터 구조로 제공하는 는 것이 핵심 목표임.
- 사용자가 정형화 규칙을 설정한 후, API를 등록하면 **외부 시스템에서 API를 호출하여 정형화된 데이터를 활용**할 수 있음.
- API 요청이 들어올 때마다 **로그가 MongoDB에 저장**되며, 이 로그를 기반으로 API 사용 현황을 모니터링할 수 있음.
- API 종류는 **4가지**이며, 각각 별도의 **콜렉션(collection)** 에 저장되며, 각 API의 호출 빈도 및 응답 속도 등을 실시간으로 추적할 수 있음.


### MongoDB를 선택하는 이유

- **비정형 데이터 저장에 최적화된 NoSQL 데이터베이스**로, 문서(Document) 기반 저장 방식이 API 로그 데이터와 잘 맞음.
- **스키마가 유연하여** API 요청 및 응답 구조가 변경되더라도 쉽게 확장 가능함.
- **수평 확장(Sharding)이 용이하여** 대량의 API 로그를 저장하고 검색하는 데 적합함.
- **쓰기 성능이 뛰어나며**, 대량의 로그 데이터가 지속적으로 쌓이는 환경에서도 안정적인 성능을 유지할 수 있음.
- 기존의 관계형 데이터베이스(RDBMS)보다 **JSON 기반의 데이터 처리 및 검색이 용이**하여, 로그 분석 및 조회 성능을 향상할 수 있음.


### 현재 대시보드에서 발생하는 성능 문제

- 현재 **콜렉션에 인덱스가 걸려 있지 않음**.
- 쿼리 실행 시 **전체 Full Scan 발생**, 데이터가 많아질수록 성능 저하가 우려됨.
- 대시보드에서 실시간 데이터 조회 시 **응답 속도가 느려지고**, 특정 필드 검색 시 부하가 증가함.
- 데이터가 많아질수록 **쿼리 실행 시간이 점점 증가**하여, 장기적으로 서비스 성능에 부정적인 영향을 미칠 가능성이 있음.

---

[[몽고디비의 데이터 관계 모델링 💯 정리]]